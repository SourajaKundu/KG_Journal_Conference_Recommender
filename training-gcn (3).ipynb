{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":9819323,"datasetId":6016181,"databundleVersionId":10066696}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:14:33.291862Z","iopub.execute_input":"2024-11-06T04:14:33.292265Z","iopub.status.idle":"2024-11-06T04:14:33.297112Z","shell.execute_reply.started":"2024-11-06T04:14:33.292225Z","shell.execute_reply":"2024-11-06T04:14:33.296213Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\nimport numpy as np\nimport pandas as pd\nfrom torch_geometric.data import Data\nimport ast\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ndcg_score, precision_score, recall_score, f1_score\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:35:25.886318Z","iopub.execute_input":"2024-11-06T05:35:25.887070Z","iopub.status.idle":"2024-11-06T05:35:25.892727Z","shell.execute_reply.started":"2024-11-06T05:35:25.887024Z","shell.execute_reply":"2024-11-06T05:35:25.891638Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"def string_to_array(embedding_str):\n    \"\"\"Convert string representation of embedding to numpy array\"\"\"\n    # Remove any whitespace and split by spaces\n    try:\n        # Clean the string and split numbers\n        cleaned_str = embedding_str.strip('[]').replace('\\n', ' ')\n        numbers = [float(x) for x in cleaned_str.split() if x]\n        return np.array(numbers)\n    except:\n        print(f\"Error processing embedding string: {embedding_str[:100]}...\")\n        return None\n\n# Load and process the data\ndef load_and_process_data():\n    # Load the dataframe with embeddings\n    print(\"Loading dataframe...\")\n    df = pd.read_csv('/kaggle/input/journal-recomm2/updated_dataframe.csv')\n    \n    print(\"Processing embeddings...\")\n    # Convert string representation of embeddings to numpy arrays\n    df['embedding'] = df['embedding'].apply(string_to_array)\n    \n    # Remove any rows where embedding conversion failed\n    df = df.dropna(subset=['embedding'])\n    \n    print(\"Loading node mapping...\")\n    # Load node mapping\n    node_mapping = pd.read_csv('/kaggle/input/journal-recomm2/node_mapping.csv')\n    \n    print(\"Loading adjacency matrix...\")\n    # Load adjacency matrix\n    matrix_data = np.load('/kaggle/input/journal-recomm2/adjacency_matrix.npz')\n    adj_matrix = matrix_data['matrix']\n    \n    return df, node_mapping, adj_matrix\n\ndef modify_adjacency_matrix(adj_matrix):\n    num_journals = 66\n    \n    # Set journal-journal submatrix to 1\n    adj_matrix[:num_journals, :num_journals] = 1\n    \n    # Set diagonal to 0 (no self-loops)\n    np.fill_diagonal(adj_matrix, 0)\n    \n    return adj_matrix\n\ndef initialize_embeddings(df, node_mapping, embedding_dim=384):\n    num_nodes = len(node_mapping)\n    num_journals = 66\n    \n    # Initialize all embeddings\n    all_embeddings = np.zeros((num_nodes, embedding_dim))\n    \n    # For journals, initialize with small random values\n    # These will be completely replaced by learned representations\n    np.random.seed(42)\n    journal_embeddings = np.random.normal(0, 0.01, (num_journals, embedding_dim))\n    all_embeddings[:num_journals] = journal_embeddings\n    \n    # Fill paper embeddings from the dataframe\n    for idx, row in df.iterrows():\n        node_id = row['id']\n        node_idx = node_mapping[node_mapping['node_id'] == node_id].index\n        if len(node_idx) > 0:\n            all_embeddings[node_idx[0]] = row['embedding']\n    \n    return all_embeddings\n\n\ndef create_mappings(journal_info_df):\n    \"\"\"\n    Create mappings using journal info DataFrame\n    Using node_id from journal info as the index\n    \"\"\"\n    # Create journal name to index mapping using node_id from journal info\n    journal_name_to_idx = {}\n    for _, row in journal_info_df.iterrows():\n        journal_name_to_idx[row['journal_name']] = row['node_id']\n    return journal_name_to_idx\n\ndef create_correct_adjacency_matrix(df, journal_info_df, original_adj_matrix):\n    \"\"\"\n    Create corrected adjacency matrix while preserving other relations\n    Only update the paper-journal connections (first 66 columns)\n    \"\"\"\n    journal_name_to_idx = create_mappings(journal_info_df)\n    \n    num_journals = 66\n    \n    # Create a copy of the original adjacency matrix to preserve other relations\n    new_adj_matrix = original_adj_matrix.copy()\n    \n    # Zero out only the paper-journal connections\n    new_adj_matrix[num_journals:, :num_journals] = 0\n    new_adj_matrix[:num_journals, num_journals:] = 0\n    \n    print(\"Creating paper-journal connections...\")\n    connections_count = 0\n    \n    for _, row in df.iterrows():\n        paper_id = row['id']\n        journal_name = row['journal']\n        \n        if journal_name in journal_name_to_idx:\n            # Get paper index (after journal indices)\n            paper_idx = int(paper_id.replace('cs_', '')) + num_journals - 1\n            journal_idx = journal_name_to_idx[journal_name]\n            \n            # Set connection in adjacency matrix\n            new_adj_matrix[paper_idx, journal_idx] = 1\n            new_adj_matrix[journal_idx, paper_idx] = 1  # Make it symmetric\n            connections_count += 1\n    \n    return new_adj_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:15:18.680967Z","iopub.execute_input":"2024-11-06T04:15:18.681773Z","iopub.status.idle":"2024-11-06T04:15:18.697029Z","shell.execute_reply.started":"2024-11-06T04:15:18.681726Z","shell.execute_reply":"2024-11-06T04:15:18.696112Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load data\nprint(\"Loading data...\")\ndf, node_mapping, adj_matrix = load_and_process_data()\n\nadj_matrix = modify_adjacency_matrix(adj_matrix)\nembeddings = initialize_embeddings(df, node_mapping)\n\njournal_info_df = pd.read_csv('/kaggle/input/journal-recomm2/journal_nodes.csv')\nprint(\"Creating corrected adjacency matrix...\")\nadj_matrix = create_correct_adjacency_matrix(df, journal_info_df, adj_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:26:23.286426Z","iopub.execute_input":"2024-11-06T04:26:23.286791Z","iopub.status.idle":"2024-11-06T04:27:10.398615Z","shell.execute_reply.started":"2024-11-06T04:26:23.286757Z","shell.execute_reply":"2024-11-06T04:27:10.397772Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nLoading dataframe...\nProcessing embeddings...\nLoading node mapping...\nLoading adjacency matrix...\nCreating corrected adjacency matrix...\nCreating paper-journal connections...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def prepare_data(adj_matrix, embeddings, df, journal_info_df):\n    \"\"\"\n    Prepare data for PyTorch Geometric with correct labels\n    \"\"\"\n    journal_name_to_idx = create_mappings(journal_info_df)\n    num_journals = 66\n    \n    # Create edge index\n    edge_index = torch.tensor(np.array(np.where(adj_matrix > 0)), dtype=torch.long)\n    \n    # Convert embeddings to tensor\n    embeddings_tensor = torch.tensor(embeddings, dtype=torch.float)\n    \n    # Create labels\n    paper_labels = []\n    for paper_idx in range(num_journals, adj_matrix.shape[0]):\n        paper_id = f\"cs_{paper_idx - num_journals + 1}\"\n        if paper_id in df['id'].values:\n            journal_name = df[df['id'] == paper_id]['journal'].values[0]\n            if journal_name in journal_name_to_idx:\n                journal_idx = journal_name_to_idx[journal_name]\n                paper_labels.append(journal_idx)\n            else:\n                print(f\"Warning: Unknown journal name: {journal_name}\")\n                paper_labels.append(-1)\n        else:\n            paper_labels.append(-1)\n    \n    paper_labels = torch.tensor(paper_labels, dtype=torch.long)\n    return edge_index, embeddings_tensor, paper_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:27:10.410421Z","iopub.execute_input":"2024-11-06T04:27:10.410738Z","iopub.status.idle":"2024-11-06T04:27:57.793620Z","shell.execute_reply.started":"2024-11-06T04:27:10.410703Z","shell.execute_reply":"2024-11-06T04:27:57.792748Z"}},"outputs":[{"name":"stdout","text":"\nPreparing data for model...\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"class JournalGCN(nn.Module):\n    def __init__(self, num_journals, num_papers, embedding_dim=384):\n        super(JournalGCN, self).__init__()\n        \n        # Learnable journal embeddings\n        self.journal_embeddings = nn.Parameter(torch.randn(num_journals, embedding_dim) * 0.01)\n        \n        # Fixed paper embeddings (not parameters)\n        self.register_buffer('paper_embeddings', torch.zeros(num_papers, embedding_dim))\n        \n        # GCN layers\n        self.conv1 = GCNConv(embedding_dim, embedding_dim)\n        self.conv2 = GCNConv(embedding_dim, embedding_dim)\n        \n        # Batch normalization and dropout\n        self.batch_norm = nn.BatchNorm1d(embedding_dim)\n        self.dropout = nn.Dropout(0.2)\n\n    def set_paper_embeddings(self, embeddings):\n        \"\"\"Set the fixed paper embeddings\"\"\"\n        self.paper_embeddings.copy_(embeddings)\n\n    def forward(self, edge_index):\n        # Combine journal and paper embeddings\n        x = torch.cat([self.journal_embeddings, self.paper_embeddings], dim=0)\n        \n        # First GCN layer\n        x = self.conv1(x, edge_index)\n        x = self.batch_norm(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        \n        # Second GCN layer\n        x = self.conv2(x, edge_index)\n        \n        # L2 normalize embeddings\n        x = F.normalize(x, p=2, dim=1)\n        \n        # Split back into journal and paper embeddings\n        journal_emb = x[:len(self.journal_embeddings)]\n        paper_emb = x[len(self.journal_embeddings):]\n        \n        return journal_emb, paper_emb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:27:57.795325Z","iopub.execute_input":"2024-11-06T04:27:57.795643Z","iopub.status.idle":"2024-11-06T04:27:57.805528Z","shell.execute_reply.started":"2024-11-06T04:27:57.795611Z","shell.execute_reply":"2024-11-06T04:27:57.804472Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def prepare_data_with_split(adj_matrix, embeddings, df, journal_info_df, val_size=0.1, test_size=0.1):\n    \"\"\"\n    Prepare data for PyTorch Geometric with train/val/test splits,\n    handling cases where some journals have too few papers\n    \"\"\"\n    journal_name_to_idx = create_mappings(journal_info_df)\n    num_journals = 66\n    \n    # Create edge index\n    edge_index = torch.tensor(np.array(np.where(adj_matrix > 0)), dtype=torch.long)\n    \n    # Convert embeddings to tensor\n    embeddings_tensor = torch.tensor(embeddings, dtype=torch.float)\n    \n    # Create labels and indices for papers\n    paper_labels = []\n    paper_indices = []\n    \n    for paper_idx in range(num_journals, adj_matrix.shape[0]):\n        paper_id = f\"cs_{paper_idx - num_journals + 1}\"\n        if paper_id in df['id'].values:\n            journal_name = df[df['id'] == paper_id]['journal'].values[0]\n            if journal_name in journal_name_to_idx:\n                journal_idx = journal_name_to_idx[journal_name]\n                paper_labels.append(journal_idx)\n                paper_indices.append(paper_idx - num_journals)\n    \n    paper_labels = np.array(paper_labels)\n    paper_indices = np.array(paper_indices)\n    \n    # Count samples per class\n    unique_labels, label_counts = np.unique(paper_labels, return_counts=True)\n    \n    # Identify labels with enough samples for stratification (at least 3 samples)\n    stratifiable_mask = np.isin(paper_labels, unique_labels[label_counts >= 3])\n    \n    # Split indices into stratifiable and non-stratifiable\n    stratifiable_indices = paper_indices[stratifiable_mask]\n    stratifiable_labels = paper_labels[stratifiable_mask]\n    non_stratifiable_indices = paper_indices[~stratifiable_mask]\n    \n    # First split: train and temporary (val+test) for stratifiable data\n    if len(stratifiable_indices) > 0:\n        train_indices, temp_indices = train_test_split(\n            stratifiable_indices,\n            test_size=(val_size + test_size),\n            stratify=stratifiable_labels,\n            random_state=42\n        )\n        \n        # Second split: val and test from temporary\n        val_indices, test_indices = train_test_split(\n            temp_indices,\n            test_size=test_size/(val_size + test_size),\n            random_state=42\n        )\n    else:\n        train_indices = np.array([])\n        val_indices = np.array([])\n        test_indices = np.array([])\n    \n    # Handle non-stratifiable data: random split\n    if len(non_stratifiable_indices) > 0:\n        non_strat_train, non_strat_temp = train_test_split(\n            non_stratifiable_indices,\n            test_size=(val_size + test_size),\n            random_state=42\n        )\n        \n        non_strat_val, non_strat_test = train_test_split(\n            non_strat_temp,\n            test_size=test_size/(val_size + test_size),\n            random_state=42\n        )\n        \n        # Combine stratifiable and non-stratifiable splits\n        train_indices = np.concatenate([train_indices, non_strat_train])\n        val_indices = np.concatenate([val_indices, non_strat_val])\n        test_indices = np.concatenate([test_indices, non_strat_test])\n    \n    # Create masks\n    train_mask = torch.zeros(len(paper_indices), dtype=torch.bool)\n    val_mask = torch.zeros(len(paper_indices), dtype=torch.bool)\n    test_mask = torch.zeros(len(paper_indices), dtype=torch.bool)\n    \n    # Convert indices to positions in the original array\n    train_positions = np.where(np.isin(paper_indices, train_indices))[0]\n    val_positions = np.where(np.isin(paper_indices, val_indices))[0]\n    test_positions = np.where(np.isin(paper_indices, test_indices))[0]\n    \n    train_mask[train_positions] = True\n    val_mask[val_positions] = True\n    test_mask[test_positions] = True\n    \n    # Convert labels to tensor\n    paper_labels = torch.tensor(paper_labels, dtype=torch.long)\n    \n    # Print split statistics\n    print(f\"\\nSplit Statistics:\")\n    print(f\"Total samples: {len(paper_labels)}\")\n    print(f\"Train samples: {train_mask.sum().item()}\")\n    print(f\"Validation samples: {val_mask.sum().item()}\")\n    print(f\"Test samples: {test_mask.sum().item()}\")\n    \n    return edge_index, embeddings_tensor, paper_labels, train_mask, val_mask, test_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:09:26.150184Z","iopub.execute_input":"2024-11-06T05:09:26.150607Z","iopub.status.idle":"2024-11-06T05:09:26.168611Z","shell.execute_reply.started":"2024-11-06T05:09:26.150568Z","shell.execute_reply":"2024-11-06T05:09:26.167662Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Replace the original data preparation with:\nedge_index, embeddings_tensor, paper_labels, train_mask, val_mask, test_mask = prepare_data_with_split(\n    adj_matrix, \n    embeddings,\n    df,\n    journal_info_df\n)\n\n# Create model\nnum_journals = 66\nnum_papers = len(paper_labels)\nmodel = JournalGCN(num_journals, num_papers)\n\n# Set paper embeddings\npaper_embeddings = embeddings_tensor[num_journals:]\nmodel.set_paper_embeddings(paper_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:09:26.696785Z","iopub.execute_input":"2024-11-06T05:09:26.697690Z","iopub.status.idle":"2024-11-06T05:10:15.590806Z","shell.execute_reply.started":"2024-11-06T05:09:26.697647Z","shell.execute_reply":"2024-11-06T05:10:15.589807Z"}},"outputs":[{"name":"stdout","text":"\nSplit Statistics:\nTotal samples: 14012\nTrain samples: 11209\nValidation samples: 1401\nTest samples: 1402\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"def train_model_with_validation(model, edge_index, paper_labels, train_mask, val_mask, num_epochs=500, lr=0.01):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    edge_index = edge_index.to(device)\n    paper_labels = paper_labels.to(device)\n    train_mask = train_mask.to(device)\n    val_mask = val_mask.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n    \n    best_val_acc = 0\n    best_model_state = None\n    patience = 50\n    counter = 0\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        optimizer.zero_grad()\n        \n        journal_embeddings, paper_embeddings = model(edge_index)\n        similarities = torch.mm(paper_embeddings, journal_embeddings.t())\n        temperature = 0.1\n        logits = similarities / temperature\n        \n        # Calculate loss only on training set\n        train_loss = F.cross_entropy(logits[train_mask], paper_labels[train_mask])\n        \n        train_loss.backward()\n        optimizer.step()\n        \n        # Evaluation\n        model.eval()\n        with torch.no_grad():\n            # Training accuracy\n            train_pred = torch.argmax(similarities[train_mask], dim=1)\n            train_acc = (train_pred == paper_labels[train_mask]).float().mean()\n            \n            # Validation accuracy\n            val_pred = torch.argmax(similarities[val_mask], dim=1)\n            val_acc = (val_pred == paper_labels[val_mask]).float().mean()\n            \n            # Save best model\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                best_model_state = model.state_dict()\n                counter = 0\n            else:\n                counter += 1\n            \n            # Early stopping\n            if counter >= patience:\n                print(f\"Early stopping at epoch {epoch}\")\n                break\n        \n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch {epoch+1}/{num_epochs}:')\n            print(f'Train Loss: {train_loss.item():.4f}')\n            print(f'Train Accuracy: {train_acc.item():.4f}')\n            print(f'Validation Accuracy: {val_acc.item():.4f}')\n    \n    # Load best model\n    model.load_state_dict(best_model_state)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:16:15.415056Z","iopub.execute_input":"2024-11-06T05:16:15.415442Z","iopub.status.idle":"2024-11-06T05:16:15.428107Z","shell.execute_reply.started":"2024-11-06T05:16:15.415405Z","shell.execute_reply":"2024-11-06T05:16:15.427100Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Replace the original training call with:\ntrained_model = train_model_with_validation(\n    model, \n    edge_index, \n    paper_labels, \n    train_mask, \n    val_mask\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:16:16.480788Z","iopub.execute_input":"2024-11-06T05:16:16.481193Z","iopub.status.idle":"2024-11-06T05:16:36.912353Z","shell.execute_reply.started":"2024-11-06T05:16:16.481135Z","shell.execute_reply":"2024-11-06T05:16:36.911405Z"}},"outputs":[{"name":"stdout","text":"Epoch 10/500:\nTrain Loss: 2.3903\nTrain Accuracy: 0.3761\nValidation Accuracy: 0.3555\nEpoch 20/500:\nTrain Loss: 1.7582\nTrain Accuracy: 0.5596\nValidation Accuracy: 0.5175\nEpoch 30/500:\nTrain Loss: 1.7611\nTrain Accuracy: 0.5544\nValidation Accuracy: 0.5111\nEpoch 40/500:\nTrain Loss: 1.3083\nTrain Accuracy: 0.6649\nValidation Accuracy: 0.6517\nEpoch 50/500:\nTrain Loss: 1.5415\nTrain Accuracy: 0.6173\nValidation Accuracy: 0.5846\nEpoch 60/500:\nTrain Loss: 1.1982\nTrain Accuracy: 0.7283\nValidation Accuracy: 0.6959\nEpoch 70/500:\nTrain Loss: 1.0674\nTrain Accuracy: 0.7478\nValidation Accuracy: 0.7302\nEpoch 80/500:\nTrain Loss: 1.1019\nTrain Accuracy: 0.7459\nValidation Accuracy: 0.7116\nEpoch 90/500:\nTrain Loss: 1.0384\nTrain Accuracy: 0.7338\nValidation Accuracy: 0.7088\nEpoch 100/500:\nTrain Loss: 1.0650\nTrain Accuracy: 0.7539\nValidation Accuracy: 0.7402\nEpoch 110/500:\nTrain Loss: 1.0417\nTrain Accuracy: 0.7659\nValidation Accuracy: 0.7302\nEpoch 120/500:\nTrain Loss: 0.9960\nTrain Accuracy: 0.7771\nValidation Accuracy: 0.7495\nEpoch 130/500:\nTrain Loss: 0.9798\nTrain Accuracy: 0.7879\nValidation Accuracy: 0.7602\nEpoch 140/500:\nTrain Loss: 0.8256\nTrain Accuracy: 0.8086\nValidation Accuracy: 0.7916\nEpoch 150/500:\nTrain Loss: 0.8529\nTrain Accuracy: 0.7877\nValidation Accuracy: 0.7659\nEpoch 160/500:\nTrain Loss: 0.8142\nTrain Accuracy: 0.8200\nValidation Accuracy: 0.7937\nEpoch 170/500:\nTrain Loss: 0.9143\nTrain Accuracy: 0.7639\nValidation Accuracy: 0.7516\nEpoch 180/500:\nTrain Loss: 0.7562\nTrain Accuracy: 0.8035\nValidation Accuracy: 0.7930\nEpoch 190/500:\nTrain Loss: 0.7662\nTrain Accuracy: 0.8574\nValidation Accuracy: 0.8480\nEpoch 200/500:\nTrain Loss: 1.0306\nTrain Accuracy: 0.7810\nValidation Accuracy: 0.7659\nEpoch 210/500:\nTrain Loss: 0.8351\nTrain Accuracy: 0.8286\nValidation Accuracy: 0.8094\nEpoch 220/500:\nTrain Loss: 0.9689\nTrain Accuracy: 0.8208\nValidation Accuracy: 0.8023\nEpoch 230/500:\nTrain Loss: 0.8322\nTrain Accuracy: 0.8136\nValidation Accuracy: 0.7937\nEarly stopping at epoch 239\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# MODIFIED FUNCTION - Replaced original evaluate_model\ndef evaluate_model_split(model, edge_index, paper_labels, mask, k=5):\n    \"\"\"Evaluate model with top-k accuracy on a specific split\"\"\"\n    device = next(model.parameters()).device\n    \n    edge_index = edge_index.to(device)\n    paper_labels = paper_labels.to(device)\n    mask = mask.to(device)\n    \n    model.eval()\n    with torch.no_grad():\n        journal_embeddings, paper_embeddings = model(edge_index)\n        similarities = torch.mm(paper_embeddings, journal_embeddings.t())\n        \n        # Get top-k predictions for masked samples\n        _, top_k_indices = torch.topk(similarities[mask], k, dim=1)\n        correct = torch.any(top_k_indices == paper_labels[mask].unsqueeze(1), dim=1)\n        accuracy = correct.float().mean()\n        \n        return accuracy.item()\n\n# Separate function for final evaluation on test set\ndef final_evaluation(model, edge_index, paper_labels, test_mask):\n    \"\"\"\n    Perform final evaluation on test set with different k values\n    Should only be called once after training is complete\n    \"\"\"\n    print(\"\\nFinal Test Set Evaluation:\")\n    metrics = {}\n    for k in [1, 3, 5, 10]:\n        acc = evaluate_model_split(model, edge_index, paper_labels, test_mask, k=k)\n        metrics[f'top_{k}_accuracy'] = acc\n        print(f\"Top-{k} Accuracy: {acc:.4f}\")\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:17:40.603013Z","iopub.execute_input":"2024-11-06T05:17:40.603910Z","iopub.status.idle":"2024-11-06T05:17:40.612728Z","shell.execute_reply.started":"2024-11-06T05:17:40.603866Z","shell.execute_reply":"2024-11-06T05:17:40.611824Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"print(\"Performing final evaluation on test set...\")\ntest_metrics = final_evaluation(trained_model, edge_index, paper_labels, test_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:17:45.191629Z","iopub.execute_input":"2024-11-06T05:17:45.192381Z","iopub.status.idle":"2024-11-06T05:17:45.386767Z","shell.execute_reply.started":"2024-11-06T05:17:45.192340Z","shell.execute_reply":"2024-11-06T05:17:45.385814Z"}},"outputs":[{"name":"stdout","text":"Performing final evaluation on test set...\n\nFinal Test Set Evaluation:\nTop-1 Accuracy: 0.8466\nTop-3 Accuracy: 0.9287\nTop-5 Accuracy: 0.9501\nTop-10 Accuracy: 0.9772\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"def compute_metrics(model, edge_index, paper_labels, mask, k_values=[1, 3, 5, 10]):\n    \"\"\"\n    Compute comprehensive evaluation metrics\n    \n    Args:\n        model: Trained GCN model\n        edge_index: Edge indices tensor\n        paper_labels: Ground truth journal labels\n        mask: Mask for selecting evaluation samples\n        k_values: List of k values for top-k metrics\n    \n    Returns:\n        dict: Dictionary containing all computed metrics\n    \"\"\"\n    device = next(model.parameters()).device\n    edge_index = edge_index.to(device)\n    paper_labels = paper_labels.to(device)\n    mask = mask.to(device)\n    \n    model.eval()\n    metrics = {}\n    \n    with torch.no_grad():\n        # Get model predictions\n        journal_embeddings, paper_embeddings = model(edge_index)\n        similarities = torch.mm(paper_embeddings[mask], journal_embeddings.t())\n        \n        # Convert to probabilities\n        probabilities = F.softmax(similarities, dim=1)\n        \n        # Get ground truth labels for masked samples\n        true_labels = paper_labels[mask].cpu().numpy()\n        prob_scores = probabilities.cpu().numpy()\n        \n        # Create one-hot encoded ground truth for NDCG\n        n_samples = len(true_labels)\n        n_classes = prob_scores.shape[1]\n        y_true = np.zeros((n_samples, n_classes))\n        y_true[np.arange(n_samples), true_labels] = 1\n        \n        # Compute NDCG for different k values\n        for k in k_values:\n            ndcg = ndcg_score(y_true, prob_scores, k=k)\n            metrics[f'ndcg@{k}'] = ndcg\n        \n        # Compute Top-k accuracy\n        for k in k_values:\n            _, top_k_indices = torch.topk(similarities, k, dim=1)\n            correct = torch.any(top_k_indices == paper_labels[mask].unsqueeze(1), dim=1)\n            accuracy = correct.float().mean().item()\n            metrics[f'top_{k}_accuracy'] = accuracy\n        \n        # Compute MRR (Mean Reciprocal Rank)\n        rankings = (similarities.argsort(dim=1, descending=True) == paper_labels[mask].unsqueeze(1)).nonzero()\n        mrr = (1.0 / (rankings[:, 1].float() + 1)).mean().item()\n        metrics['mrr'] = mrr\n        \n        # Compute MAP (Mean Average Precision)\n        ap_sum = 0\n        for i, label in enumerate(paper_labels[mask]):\n            ranking = similarities[i].argsort(descending=True)\n            rank = (ranking == label).nonzero().item() + 1\n            ap_sum += 1.0 / rank\n        map_score = ap_sum / len(paper_labels[mask])\n        metrics['map'] = map_score\n        \n        # Compute Coverage\n        _, top_k_indices = torch.topk(similarities, max(k_values), dim=1)\n        unique_recommendations = len(torch.unique(top_k_indices))\n        coverage = unique_recommendations / len(journal_embeddings)\n        metrics['coverage'] = coverage\n        \n        # Compute Average Rank of True Label\n        ranks = []\n        for i, label in enumerate(paper_labels[mask]):\n            ranking = similarities[i].argsort(descending=True)\n            rank = (ranking == label).nonzero().item() + 1\n            ranks.append(rank)\n        avg_rank = np.mean(ranks)\n        metrics['average_rank'] = avg_rank\n        \n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:37:41.317891Z","iopub.execute_input":"2024-11-06T05:37:41.319005Z","iopub.status.idle":"2024-11-06T05:37:41.334770Z","shell.execute_reply.started":"2024-11-06T05:37:41.318960Z","shell.execute_reply":"2024-11-06T05:37:41.333802Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"def evaluate_recommendations(model, edge_index, paper_labels, masks):\n    \"\"\"\n    Evaluate model performance on all data splits\n    \n    Args:\n        model: Trained GCN model\n        edge_index: Edge indices tensor\n        paper_labels: Ground truth journal labels\n        masks: Dictionary containing train/val/test masks\n    \"\"\"\n    k_values = list(range(1, 11))  # k from 1 to 10\n    \n    results = {}\n    for split_name, mask in masks.items():\n        print(f\"\\n{split_name} Set Metrics:\")\n        metrics = compute_metrics(model, edge_index, paper_labels, mask, k_values)\n        \n        # Print metrics in a formatted way\n        print(\"\\nTop-k Accuracy:\")\n        for k in k_values:\n            print(f\"Top-{k}: {metrics[f'top_{k}_accuracy']:.4f}\")\n        \n        print(\"\\nNDCG Scores:\")\n        for k in k_values:\n            print(f\"NDCG@{k}: {metrics[f'ndcg@{k}']:.4f}\")\n        \n        print(\"\\nOther Metrics:\")\n        print(f\"MRR: {metrics['mrr']:.4f}\")\n        print(f\"MAP: {metrics['map']:.4f}\")\n        print(f\"Coverage: {metrics['coverage']:.4f}\")\n        \n        results[split_name] = metrics\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:37:41.808851Z","iopub.execute_input":"2024-11-06T05:37:41.809819Z","iopub.status.idle":"2024-11-06T05:37:41.817296Z","shell.execute_reply.started":"2024-11-06T05:37:41.809775Z","shell.execute_reply":"2024-11-06T05:37:41.816235Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"\n# After training the model\nmasks = {\n    'Train': train_mask,\n    'Validation': val_mask,\n    'Test': test_mask\n}\n\nevaluation_results = evaluate_recommendations(\n    model=trained_model,\n    edge_index=edge_index,\n    paper_labels=paper_labels,\n    masks=masks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:37:42.345827Z","iopub.execute_input":"2024-11-06T05:37:42.346682Z","iopub.status.idle":"2024-11-06T05:37:57.947504Z","shell.execute_reply.started":"2024-11-06T05:37:42.346638Z","shell.execute_reply":"2024-11-06T05:37:57.946454Z"}},"outputs":[{"name":"stdout","text":"\nTrain Set Metrics:\n\nTop-k Accuracy:\nTop-1: 0.8508\nTop-2: 0.9030\nTop-3: 0.9300\nTop-4: 0.9437\nTop-5: 0.9524\nTop-6: 0.9588\nTop-7: 0.9633\nTop-8: 0.9675\nTop-9: 0.9723\nTop-10: 0.9761\n\nNDCG Scores:\nNDCG@1: 0.8508\nNDCG@2: 0.8838\nNDCG@3: 0.8972\nNDCG@4: 0.9032\nNDCG@5: 0.9065\nNDCG@6: 0.9088\nNDCG@7: 0.9103\nNDCG@8: 0.9116\nNDCG@9: 0.9131\nNDCG@10: 0.9142\n\nOther Metrics:\nMRR: 0.8958\nMAP: 0.8958\nCoverage: 1.0000\n\nValidation Set Metrics:\n\nTop-k Accuracy:\nTop-1: 0.8430\nTop-2: 0.8936\nTop-3: 0.9179\nTop-4: 0.9293\nTop-5: 0.9415\nTop-6: 0.9500\nTop-7: 0.9557\nTop-8: 0.9607\nTop-9: 0.9636\nTop-10: 0.9700\n\nNDCG Scores:\nNDCG@1: 0.8430\nNDCG@2: 0.8749\nNDCG@3: 0.8871\nNDCG@4: 0.8920\nNDCG@5: 0.8967\nNDCG@6: 0.8997\nNDCG@7: 0.9016\nNDCG@8: 0.9032\nNDCG@9: 0.9041\nNDCG@10: 0.9059\n\nOther Metrics:\nMRR: 0.8875\nMAP: 0.8875\nCoverage: 1.0000\n\nTest Set Metrics:\n\nTop-k Accuracy:\nTop-1: 0.8466\nTop-2: 0.9016\nTop-3: 0.9287\nTop-4: 0.9401\nTop-5: 0.9501\nTop-6: 0.9586\nTop-7: 0.9665\nTop-8: 0.9686\nTop-9: 0.9750\nTop-10: 0.9772\n\nNDCG Scores:\nNDCG@1: 0.8466\nNDCG@2: 0.8813\nNDCG@3: 0.8949\nNDCG@4: 0.8998\nNDCG@5: 0.9036\nNDCG@6: 0.9067\nNDCG@7: 0.9093\nNDCG@8: 0.9100\nNDCG@9: 0.9119\nNDCG@10: 0.9125\n\nOther Metrics:\nMRR: 0.8932\nMAP: 0.8932\nCoverage: 1.0000\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"def save_model_outputs(model, edge_index, test_mask, journal_info_df, save_dir='outputs'):\n    \"\"\"\n    Save journal embeddings and test indices with proper device management\n    \"\"\"\n    import os\n    \n    # Create output directory if it doesn't exist\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Determine device\n    device = next(model.parameters()).device\n    \n    # Move tensors to the same device as the model\n    edge_index = edge_index.to(device)\n    test_mask = test_mask.to(device)\n    \n    # Get journal embeddings\n    model.eval()\n    with torch.no_grad():\n        journal_embeddings, _ = model(edge_index)\n        # Move embeddings to CPU before converting to numpy\n        journal_embeddings = journal_embeddings.cpu().numpy()\n    \n    # Create DataFrame with journal embeddings\n    journal_embeddings_df = pd.DataFrame(\n        journal_embeddings,\n        columns=[f'dim_{i}' for i in range(journal_embeddings.shape[1])]\n    )\n    \n    # Add journal information\n    journal_embeddings_df['journal_name'] = journal_info_df['journal_name'].values\n    journal_embeddings_df['node_id'] = journal_info_df['node_id'].values\n    \n    # Save journal embeddings\n    embeddings_path = os.path.join(save_dir, 'journal_embeddings.csv')\n    journal_embeddings_df.to_csv(embeddings_path, index=False)\n    print(f\"Saved journal embeddings to {embeddings_path}\")\n    \n    # Get and save test indices (move to CPU first)\n    test_indices = torch.where(test_mask.cpu())[0].numpy()\n    indices_path = os.path.join(save_dir, 'test_indices.npy')\n    np.save(indices_path, test_indices)\n    print(f\"Saved test indices to {indices_path}\")\n    \n    # Save test indices with paper IDs\n    test_indices_df = pd.DataFrame({\n        'index': test_indices,\n        'paper_id': [f'cs_{idx - 65}' for idx in test_indices]  # -65 because first 66 nodes are journals\n    })\n    indices_csv_path = os.path.join(save_dir, 'test_indices.csv')\n    test_indices_df.to_csv(indices_csv_path, index=False)\n    print(f\"Saved test indices with paper IDs to {indices_csv_path}\")\n    \n    return journal_embeddings_df, test_indices, test_indices_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:22:31.164539Z","iopub.execute_input":"2024-11-06T05:22:31.165187Z","iopub.status.idle":"2024-11-06T05:22:31.175978Z","shell.execute_reply.started":"2024-11-06T05:22:31.165132Z","shell.execute_reply":"2024-11-06T05:22:31.175149Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# After training the model\nx,y,z = save_model_outputs(\n    model=trained_model,\n    edge_index=edge_index,\n    test_mask=test_mask,\n    journal_info_df=journal_info_df,\n    save_dir='/kaggle/working/'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:23:03.522597Z","iopub.execute_input":"2024-11-06T05:23:03.522991Z","iopub.status.idle":"2024-11-06T05:23:03.618332Z","shell.execute_reply.started":"2024-11-06T05:23:03.522954Z","shell.execute_reply":"2024-11-06T05:23:03.617437Z"}},"outputs":[{"name":"stdout","text":"Saved journal embeddings to /kaggle/working/journal_embeddings.csv\nSaved test indices to /kaggle/working/test_indices.npy\nSaved test indices with paper IDs to /kaggle/working/test_indices.csv\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"\n# To load the saved files later:\ndef load_saved_outputs(load_dir='outputs'):\n    \"\"\"\n    Load the saved journal embeddings and test indices\n    \"\"\"\n    # Load journal embeddings\n    embeddings_path = os.path.join(load_dir, 'journal_embeddings.csv')\n    journal_embeddings_df = pd.read_csv(embeddings_path)\n    \n    # Load test indices\n    indices_path = os.path.join(load_dir, 'test_indices.npy')\n    test_indices = np.load(indices_path)\n    \n    # Load test indices with paper IDs\n    indices_csv_path = os.path.join(load_dir, 'test_indices.csv')\n    test_indices_df = pd.read_csv(indices_csv_path)\n    \n    return journal_embeddings_df, test_indices, test_indices_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:23:19.206289Z","iopub.execute_input":"2024-11-06T05:23:19.206682Z","iopub.status.idle":"2024-11-06T05:23:19.213126Z","shell.execute_reply.started":"2024-11-06T05:23:19.206644Z","shell.execute_reply":"2024-11-06T05:23:19.212012Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# Example of loading:\n\njournal_embeddings_df, test_indices, test_indices_df = load_saved_outputs('/kaggle/working/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:23:42.680264Z","iopub.execute_input":"2024-11-06T05:23:42.680650Z","iopub.status.idle":"2024-11-06T05:23:42.706023Z","shell.execute_reply.started":"2024-11-06T05:23:42.680613Z","shell.execute_reply":"2024-11-06T05:23:42.705139Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}